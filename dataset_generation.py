# -*- coding: utf-8 -*-
"""Dataset Generation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/arnavsharmaa/dataset-generation.a7768beb-8b04-40cc-8071-db6a7258560c.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250416/auto/storage/goog4_request%26X-Goog-Date%3D20250416T162636Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9f94ee32c21605501dc4843067ac7702f6e021f59c3c1a90a2186469d9383b06edf2966d79a2528285890bafb8a2993e57cf2f2e1c1fbd59936d1736f938e364885ef9bce39d989c8e0246ad5a6676c1bde1f17fb0a8e907997ae846b7d11a594c9fdb367dbdae2168b2df895354810c2e3999df0f59fec876c95b94476ba4c7122ceb74440a53abb8626e4e028c14df41c4e1422718c8840ab97028b92872b2b4198940d4e58c8961961e0383d5dd75f47955e85b803e4076fb0143a66c65f303cdf0b7d8ce187ae707b59e21cf8209ba8364bdc8e6953f2e71d135525e598085b6abe21cf85468ade1bc26e147be2c1be9f5e11ccd2b30a608dd23642219b8
"""

pip install git+https://github.com/huggingface/parler-tts.git

import os
import torch
import textwrap
import soundfile as sf
import numpy as np
from tqdm import tqdm
from datasets import load_dataset
from transformers import AutoTokenizer
from parler_tts import ParlerTTSForConditionalGeneration

device = "cuda" if torch.cuda.is_available() else "cpu"

tts_model = ParlerTTSForConditionalGeneration.from_pretrained("ai4bharat/indic-parler-tts").to(device)
desc_tokenizer = AutoTokenizer.from_pretrained(tts_model.config.text_encoder._name_or_path)
prompt_tokenizer = AutoTokenizer.from_pretrained("ai4bharat/indic-parler-tts")

def get_description(speaker, lang):
    return f"{speaker}'s voice in {lang} is clear, moderately paced, and expressive."

OUTPUT_DIR = "dataset"
os.makedirs(OUTPUT_DIR, exist_ok=True)

xlsum_languages = {
    "hi": "hindi",
    "pa": "punjabi",
    "ur": "urdu",
    "bn": "bengali",
    "ta": "tamil",
    "te": "telugu",
    "mr": "marathi",
    "en": "english"
}

sample_limit = 30
sample_id = 0

speaker_map = {
    "hi": "Rohit",
    "bn": "Arjun",
    "en": "Thoma",
    "pa": "Divjot",
    "ta": "Jaya",
    "te": "Prakash",
    "mr": "Sanjay"
}

for lang_code, lang_name in xlsum_languages.items():
    print(f"\nProcessing: {lang_name} ({lang_code})")
    dataset = load_dataset("csebuetnlp/xlsum", lang_name, split=f"train[:{sample_limit}]")

    for data in tqdm(dataset):
        article = data["text"]
        summary = data["summary"]
        speaker = speaker_map.get(lang_code, "Anita")

        sample_folder = os.path.join(OUTPUT_DIR, f"sample_{sample_id:04d}")
        os.makedirs(sample_folder, exist_ok=True)

        with open(os.path.join(sample_folder, "input.txt"), "w", encoding="utf-8") as f:
            f.write(article)

        with open(os.path.join(sample_folder, "summary.txt"), "w", encoding="utf-8") as f:
            f.write(summary)

        with open(os.path.join(sample_folder, "lang.txt"), "w", encoding="utf-8") as f:
            f.write(lang_code)

        description = get_description(speaker, lang_name)
        desc_ids = desc_tokenizer(description, return_tensors="pt").to(device)

        chunks = textwrap.wrap(article, width=512, break_long_words=False)
        chunk_audios = []

        for chunk in chunks:
            prompt_ids_chunk = prompt_tokenizer(chunk, return_tensors="pt", truncation=True, max_length=512).to(device)
            chunk_audio = tts_model.generate(
                input_ids=desc_ids.input_ids,
                attention_mask=desc_ids.attention_mask,
                prompt_input_ids=prompt_ids_chunk.input_ids,
                prompt_attention_mask=prompt_ids_chunk.attention_mask
            ).cpu().numpy().squeeze()
            chunk_audios.append(chunk_audio)

        audio_input = np.concatenate(chunk_audios, axis=-1)
        sf.write(os.path.join(sample_folder, "input.wav"), audio_input, tts_model.config.sampling_rate)

        prompt_ids_summary = prompt_tokenizer(summary, return_tensors="pt", truncation=True, max_length=256).to(device)
        audio_summary = tts_model.generate(
            input_ids=desc_ids.input_ids,
            attention_mask=desc_ids.attention_mask,
            prompt_input_ids=prompt_ids_summary.input_ids,
            prompt_attention_mask=prompt_ids_summary.attention_mask
        ).cpu().numpy().squeeze()
        sf.write(os.path.join(sample_folder, "summary.wav"), audio_summary, tts_model.config.sampling_rate)

        sample_id += 1

import shutil

shutil.make_archive("/kaggle/working/dataset", 'zip', "/kaggle/working/dataset")